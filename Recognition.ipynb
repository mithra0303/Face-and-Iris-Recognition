import bz2
import os

from urllib.request import urlopen

def download_landmarks(dst_file):
    url = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'
    decompressor = bz2.BZ2Decompressor()
    
    with urlopen(url) as src, open(dst_file, 'wb') as dst:
        data = src.read(1024)
        while len(data) > 0:
            dst.write(decompressor.decompress(data))
            data = src.read(1024)

dst_dir = 'F:/face2/face-recognition-master/models'
dst_file = os.path.join(dst_dir, 'landmarks.dat')

if not os.path.exists(dst_file):
    os.makedirs(dst_dir)
    download_landmarks(dst_file)
from model import create_model

nn4_small2 = create_model()
from keras import backend as K
from keras.models import Model
from keras.layers import Input, Layer

# Input for anchor, positive and negative images
in_a = Input(shape=(96, 96, 3))
in_p = Input(shape=(96, 96, 3))
in_n = Input(shape=(96, 96, 3))

# Output for anchor, positive and negative embedding vectors
# The nn4_small model instance is shared (Siamese network)
emb_a = nn4_small2(in_a)
emb_p = nn4_small2(in_p)
emb_n = nn4_small2(in_n)

class TripletLossLayer(Layer):
    def __init__(self, alpha, **kwargs):
        self.alpha = alpha
        super(TripletLossLayer, self).__init__(**kwargs)
    
    def triplet_loss(self, inputs):
        a, p, n = inputs
        p_dist = K.sum(K.square(a-p), axis=-1)
        n_dist = K.sum(K.square(a-n), axis=-1)
        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)
    
    def call(self, inputs):
        loss = self.triplet_loss(inputs)
        self.add_loss(loss)
        return loss

# Layer that computes the triplet loss from anchor, positive and negative embedding vectors
triplet_loss_layer = TripletLossLayer(alpha=0.2, name='triplet_loss_layer')([emb_a, emb_p, emb_n])

# Model that can be trained with anchor, positive negative images
nn4_small2_train = Model([in_a, in_p, in_n], triplet_loss_layer)
nn4_small2_pretrained = create_model()
nn4_small2_pretrained.load_weights('F:/face2/face-recognition-master/weights/nn4.small2.v1.h5')
import numpy as np
import os.path

class IdentityMetadata():
    def __init__(self, base, name, file):
        # dataset base directory
        self.base = base
        # identity name
        self.name = name
        # image file name
        self.file = file

    def __repr__(self):
        return self.image_path()

    def image_path(self):
        return os.path.join(self.base, self.name, self.file) 
    
def load_metadata(path):
    metadata = []
    for i in os.listdir(path):
        for f in os.listdir(os.path.join(path, i)):
            # Check file extension. Allow only jpg/jpeg' files.
            ext = os.path.splitext(f)[1]
            if ext == '.jpg' or ext == '.jpeg' or ext == '.JPG':
                metadata.append(IdentityMetadata(path, i, f))
    return np.array(metadata)

metadata = load_metadata('F:/finalprep/face80x/train')
metadata1 = load_metadata('F:/finalprep/face80x/valid')
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches

from align import AlignDlib

%matplotlib inline

def load_image(path):
    img = cv2.imread(path, 1)
    # OpenCV loads images with color channels
    # in BGR order. So we need to reverse them
    #return img[...,::-1]
    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
    #cv2.imshow("g" , img)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()
    return img

# Initialize the OpenFace face alignment utility
alignment = AlignDlib('F:/face2/face-recognition-master/models/landmarks.dat')

# Load an image of Jacques Chirac
jc_orig = load_image(metadata[2].image_path())

# Detect face and return bounding box
bb = alignment.getLargestFaceBoundingBox(jc_orig)

# Transform image using specified face landmark indices and crop image to 96x96
jc_aligned = alignment.align(96, jc_orig, bb, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)

# Show original image
plt.subplot(131)
plt.imshow(jc_orig)

# Show original image with bounding box
plt.subplot(132)
plt.imshow(jc_orig)
plt.gca().add_patch(patches.Rectangle((bb.left(), bb.top()), bb.width(), bb.height(), fill=False, color='red'))

# Show aligned image
plt.subplot(133)
plt.imshow(jc_aligned);


def align_image(img):
    return alignment.align(96, img, alignment.getLargestFaceBoundingBox(img), 
                           landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)
import cv2
good_image_indx = []
unfit_image_indx = []
count=0
ass=[]
embedded = np.zeros((metadata.shape[0], 128))
for i, m in enumerate(metadata):
    try:
        img = load_image(m.image_path())
        img = align_image(img)
    except:
        print("for new error",m.image_path())
    try:
        img = (img / 255.).astype(np.float32)
    except TypeError:
        unfit_image_indx.append(i)
        count+=1
        print(m.image_path())
        print("The image is not Clear to extract the Embeddings")
    else:
        embedded[i] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]
        good_image_indx.append(i)
        #ass.append(embedded[i])
print(len(embedded[i]))
#print(ass.shape)
#print(len(ass))
        
#metadata = metadata[good_image_indx]
#embedded = embedded[good_image_indx]
print(count)
#for validation of face
good_image_indx = []
unfit_image_indx = []
count=0
ass=[]
embedded1 = np.zeros((metadata1.shape[0], 128))
for i, m in enumerate(metadata1):
    img = load_image(m.image_path())
    img = align_image(img)
    try:
        img = (img / 255.).astype(np.float32)
    except TypeError:
        unfit_image_indx.append(i)
        count+=1
        print(m.image_path())
        print("The image is not Clear to extract the Embeddings")
    else:
        embedded1[i] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]
        good_image_indx.append(i)
        #ass.append(embedded[i])
print(len(embedded1[i]))
#print(ass.shape)
#print(len(ass))
        
#metadata = metadata[good_image_indx]
#embedded = embedded[good_image_indx]
print(count)
print(len(embedded))
#till here face
from keras.applications import VGG16
from keras import models
from keras import layers
from keras import optimizers
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
from keras.models import Model
import numpy as np
import matplotlib.pyplot as plt

vgg_conv_new = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(224, 224, 3))
train_dir = 'F:/concatenation/iris38/train'
validation_dir = 'F:/concatenation/iris38/valid'
nTrain = 300 #folder number 24 has 4 imgs only so 
nVal = 65 #folder 1 to 10 have 1 img, 11 to 38 ,except 24(has one img) have 2 imgs
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
from random import shuffle
datagen = ImageDataGenerator(rescale=1./255)
batch_size = 4
 
train_features = np.zeros(shape=(nTrain, 7,7,512))
train_labels = np.zeros(shape=(nTrain,38))
 
train_generator = datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=None)
i = 0
nImages=300
for inputs_batch, labels_batch in train_generator:
    features_batch = vgg_conv_new.predict(inputs_batch)
    train_features[i * batch_size : (i + 1) * batch_size] = features_batch
    train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch
    i += 1
    if i * batch_size >= nImages:
        break
         
train_features = np.reshape(train_features, (nTrain, 7*7*512))
val_features = np.zeros(shape=(nVal, 7,7,512))
val_labels = np.zeros(shape=(nVal,38))
 
val_generator = datagen.flow_from_directory(
    validation_dir,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=None)
i = 0
nImages1=65
for inputs_batch, labels_batch1 in val_generator:
    features_batch1 = vgg_conv_new.predict(inputs_batch)
    val_features[i * batch_size : (i + 1) * batch_size] = features_batch1
    val_labels[i * batch_size : (i + 1) * batch_size] = labels_batch1
    i += 1
    if i * batch_size >= nImages1:
        break
         
val_features = np.reshape(val_features, (nVal, 25088))
print(val_labels)
from keras import models
from keras import layers
from keras import optimizers
from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Dropout
#from keras.layers import random
import random
model = Sequential()
model.add(layers.Dense(256, activation='relu', input_dim=7 * 7 * 512,name ='den'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(38, activation='softmax'))
model.compile(optimizer=optimizers.RMSprop(lr=2e-4),
              loss='categorical_crossentropy',
              metrics=['acc'])
 
history = model.fit(train_features,
                    train_labels,
                    epochs=15,
                    batch_size=batch_size,
                    validation_data=(val_features,val_labels))
print(train_features.shape)
print(val_features.shape)
model_new = Model(input=model.input, output=model.get_layer('den').output)
############# features for 80 classess ##############
train_dir80 = 'F:/finalprep/iris80x/train'
validation_dir80 = 'F:/finalprep/iris80x/valid'
nTrain80 = 640 #folder number 24 has 4 imgs only so 
nVal80 = 160 #folder 1 to 10 have 1 img, 11 to 38 ,except 24(has one img) have 2 imgs
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
from random import shuffle
datagen = ImageDataGenerator(rescale=1./255)
batch_size = 4
 
train_features80 = np.zeros(shape=(nTrain80, 7,7,512))
train_labels80 = np.zeros(shape=(nTrain80,80))
 
train_generator = datagen.flow_from_directory(
    train_dir80,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=None)
i = 0
nImages80=640
for inputs_batch80, labels_batch80 in train_generator:
    features_batch80 = vgg_conv_new.predict(inputs_batch80)
    train_features80[i * batch_size : (i + 1) * batch_size] = features_batch80
    train_labels80[i * batch_size : (i + 1) * batch_size] = labels_batch80
    i += 1
    if i * batch_size >= nImages80:
        break
         
train_features80 = np.reshape(train_features80, (nTrain80, 7*7*512))
val_features81 = np.zeros(shape=(nVal80, 7,7,512))
val_labels81 = np.zeros(shape=(nVal80,80))
 
val_generator = datagen.flow_from_directory(
    validation_dir80,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=None)
i = 0
nImages81=160
for inputs_batch81, labels_batch81 in val_generator:
    features_batch81 = vgg_conv_new.predict(inputs_batch81)
    val_features81[i * batch_size : (i + 1) * batch_size] = features_batch81
    val_labels81[i * batch_size : (i + 1) * batch_size] = labels_batch81
    i += 1
    if i * batch_size >= nImages81:
        break
         
val_features81 = np.reshape(val_features81, (nVal80, 25088))
print(val_labels81)
print(val_features81.shape)
print(train_features80.shape)
#####the train_features one by one are being reshaped to (1,25088),by first reshping and then transposing to get (1,25088)###
feaa=[]
for i in range(nImages80):
    fea=(np.reshape(train_features80[i], (25088,1)))
    c = (model_new.predict(fea.transpose()))
    feaa.append(c[0])
print(len(feaa),len(feaa[0]))
####same for val_features#####
valf=[]
for i in range(nImages81):
    f=(np.reshape(val_features81[i], (25088,1)))
    c = (model_new.predict(f.transpose()))
    valf.append(c[0])
###print###
valf=np.array(valf)
print('valf',valf.shape)
feaa = np.array(feaa)
print('feaa',feaa.shape)
### these labels are created for ml classifiers ,not needed if a simple nn is used, for that train_labels,va_lables is enough#
##these are the lables for training dataset#####
labels = []
for i in range(80):
    for j in range(8):
        labels.append(str(i))
print(labels)
###labels for val dataset####
tes_labels = []
for i in range(80):
    for k in range(2):
        tes_labels.append(str(i))
print(tes_labels)
#####concat#########
import numpy as np
c=[]
a=embedded
b=feaa
for i in range(len(b)):
    c.append(np.concatenate((a[i], b[i]), axis=0))
c=np.array(c)
print(len((c)))
d=[]
e=embedded1
f=valf
for i in range(len(e)):
    d.append(np.concatenate((e[i],f[i]),axis=0))
d=np.array(d)
print(len(d))
print(len(c[0]))
#####################iris 256############################
#####################classification of 256 iris#####################
###################iris 256 class############### +face down#################
import numpy as np
c=[]
a=embedded
b=feaa
for i in range(len(b)):
    c.append(np.concatenate((a[i], b[i]), axis=0))
c=np.array(c)
print(len((c)))
d=[]
e=embedded1
f=valf
for i in range(len(e)):
    d.append(np.concatenate((e[i],f[i]),axis=0))
d=np.array(d)
print(len(d))

from keras import models
from keras import layers
from keras import optimizers
from keras.models import Sequential
 
model = Sequential()
model.add(layers.Dense(256, activation='relu', input_dim=384))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(10, activation='softmax'))
model.compile(optimizer=optimizers.RMSprop(lr=2e-4),
              loss='categorical_crossentropy',
              metrics=['acc'])
 
history = model.fit(c,
                    train_labels,
                    epochs=10,
                    batch_size=batch_size,
                    validation_data=(d,val_labels))
metadata2 = load_metadata('F:/concatenation/face images/test/Vladimir_Putin/')
good_image_indx = []
unfit_image_indx = []
count=0
ass=[]
embeddedt = np.zeros((metadata2.shape[0], 128))
for i, m in enumerate(metadata2):
    img = load_image(m.image_path())
    img = align_image(img)
    try:
        img = (img / 255.).astype(np.float32)
    except TypeError:
        unfit_image_indx.append(i)
        count+=1
        print("The image is not Clear to extract the Embeddings")
    else:
        embeddedt[i] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]
        good_image_indx.append(i)
        #ass.append(embedded[i])
print(len(embeddedt[i]))
#print(ass.shape)
#print(len(ass))
        
#metadata = metadata[good_image_indx]
#embedded = embedded[good_image_indx]
print(count)
'''#test=['110_L.bmp.jpg','210_L.bmp.jpg','310_L.bmp.jpg','410_L.bmp.jpg','510_L.bmp.jpg','610_L.bmp.jpg','710_L.bmp.jpg','810_L.bmp.jpg','910_L.bmp.jpg','1010_L.bmp.jpg']
#test_path='C:/Users/HP/Pictures/sample/008/10_L.bmp.jpg'
#test=['01_L.bmp.jpg','02_L.bmp.jpg','03_L.bmp.jpg','04_L.bmp.jpg','05_L.bmp.jpg','06_L.bmp.jpg','07_L.bmp.jpg','08_L.bmp.jpg','09_L.bmp.jpg','10_L.bmp.jpg']
from keras.applications.vgg16 import VGG16
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
import numpy as np
import cv2
test_path='F:/concatenation/iris images/test/1010_L.bmp.jpg'
#test_path='C:/Users/HP/Pictures/sample/006/'
test_img=[]
from keras.applications.vgg16 import decode_predictions
temp_img=image.load_img(test_path,target_size=(224,224))
    #temp_img=image.load_img(test_path,target_size=(224,224))

test_img=image.img_to_array(temp_img)

test_img=preprocess_input(test_img)
test_img=test_img.reshape(1,224,224,3)
features = vgg_conv_new.predict(test_img)
features = np.reshape(features, (25088,1))
features = model_new.predict(features.transpose())
g=[]
h=embeddedt.tolist()
h= h[0]
features = features.tolist()
features = features[0]
#print(features,"fea:",h)
h.extend(features)
h=np.array(h)
h=np.reshape(h,(384,1))
#print(h,'len',len(h))
#new = np.concatenate(h[0],features[0])
#print(len(new),new)'''
'''ii=features
for i in range(len(ii)):
    g.append(np.concatenate((h[i],ii[i]),axis=0))
g=np.array(g)
print(len(g))'''

'''pre = (model.predict_classes(h.transpose()))

print(pre)'''
#print((h).shape)

############## ml classifier ###############
####all ml models for classifying th e 256 dimensional features#######
import h5py
import numpy as np
import os
import glob
import cv2
from matplotlib import pyplot
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.externals import joblib

# create all the machine learning models
models = []
models.append(('LR', LogisticRegression(random_state=9)))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier(random_state=9)))
models.append(('RF', RandomForestClassifier(n_estimators=5, random_state=9)))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(random_state=9)))

# variables to hold the results and names
results = []
names = []
scoring = "accuracy"
for name,i in models:
    clf=i
    clf.fit(c,labels)
    predicted=clf.predict(d)
    print("name",name,"accuracy",accuracy_score(tes_labels,predicted))

###############test###############3
metadata_test = load_metadata('F:/finalprep/face80x/test')
import cv2
good_image_indx = []
unfit_image_indx = []
count=0
ass=[]
embedded_test = np.zeros((metadata_test.shape[0], 128))
for i, m in enumerate(metadata_test):
    try:
        img = load_image(m.image_path())
        img = align_image(img)
    except:
        print("for new error",m.image_path())
    try:
        img = (img / 255.).astype(np.float32)
    except TypeError:
        unfit_image_indx.append(i)
        count+=1
        print(m.image_path())
        print("The image is not Clear to extract the Embeddings")
    else:
        embedded_test[i] = nn4_small2_pretrained.predict(np.expand_dims(img, axis=0))[0]
        good_image_indx.append(i)
        #ass.append(embedded[i])
print(len(embedded_test[i]))
#print(ass.shape)
#print(len(ass))
        
#metadata = metadata[good_image_indx]
#embedded = embedded[good_image_indx]
print(count)
####for testing images####
#1.first extract features using vgg and then reshape them then transpose it to make them compatible to be reduced to 256 using 
#model_new ,(because this modle requires that much input only)
val_features1 = np.zeros(shape=(80, 7,7,512))
val_labels1 = np.zeros(shape=(80,80))
 
val_generator1 = datagen.flow_from_directory(
    'F:/finalprep/iris80x/test',
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=None)
i = 0
nImages1=80
for inputs_batch, labels_batch1 in val_generator1:
    features_batch1 = vgg_conv_new.predict(inputs_batch)
    #eatures_batch1 = model_new.predict(features_batch1)
    val_features1[i* batch_size : (i + 1) * batch_size] = features_batch1
    val_labels1[i*batch_size : (i + 1) * batch_size] = labels_batch1
    i += 1
    if i * batch_size >= nImages1:
        break
        
############## testf is test features #############
val_features1= np.reshape(val_features1,(80, 25088))
testf=[]
for i in range(80):
    f=(np.reshape(val_features1[i], (25088,1)))
    c = (model_new.predict(f.transpose()))
    testf.append(c[0])
print(len(testf[0]))
xyz=[]
y=embedded_test
f=testf
for i in range(len(y)):
    xyz.append(np.concatenate((y[i],f[i]),axis=0))
xyz=np.array(xyz)
print(len(xyz))
print(len(xyz[0]))
testlabels = []
for i in range(80):
    testlabels.append(str(i))
print(testlabels)
for name,i in models:
    clf=i
    clf.fit(c,labels)
    predicted=clf.predict(xyz)
    print("name",name,"accuracy",accuracy_score(testlabels,predicted))
    print(clf.predict(xyz)) #print the classes
###########svm#########
params_grid = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2 ,1e-3, 1e-4],
                     'C': [1,5, 10, 100, 1000]},
                    {'kernel': ['linear'], 'C': [1,5, 10, 100, 1000]}]
from sklearn.model_selection import GridSearchCV
svm_model = GridSearchCV(SVC(), params_grid, cv=5)
svm_model.fit(c, labels)
print('Best score for training data:', svm_model.best_score_,"\n") 

# View the best parameters for the model found using grid search
print('Best C:',svm_model.best_estimator_.C,"\n") 
print('Best Kernel:',svm_model.best_estimator_.kernel,"\n")
print('Best Gamma:',svm_model.best_estimator_.gamma,"\n")

final_model = svm_model.best_estimator_
Y_pred = final_model.predict(xyz)
print(Y_pred)
print("name",name,"accuracy",accuracy_score(testlabels,Y_pred))
#Y_pred_label = list(encoder.inverse_transform(Y_pred))
param_grids = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }
clflogistic = GridSearchCV(LogisticRegression(penalty='l2'), param_grids)
clflogistic.fit(c,labels)
print('Best score for training data:', clflogistic.best_score_,"\n") 

# View the best parameters for the model found using grid search
print('Best C:',clflogistic.best_estimator_.C,"\n") 
#print('Best Kernel:',clflogistic.best_estimator_.kernel,"\n")
#print('Best Gamma:',clflogistic.best_estimator_.gamma,"\n")

final_model = clflogistic.best_estimator_
Y_pred = final_model.predict(xyz)
print(Y_pred)
print("name",name,"accuracy",accuracy_score(testlabels,Y_pred))
